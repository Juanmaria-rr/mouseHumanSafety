{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Window\n",
    "import pyspark.sql.functions as F\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    DoubleType,\n",
    "    DecimalType,\n",
    "    StringType,\n",
    "    FloatType,\n",
    ")\n",
    "from functions import directionOfEffect\n",
    "from pyspark.ml.functions import array_to_vector, vector_to_array\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can we use mouse phenotypes for: \n",
    "    >> Predict Safety Liabilities\n",
    "    >> Drug warnings (Black Box Warnings)\n",
    "    >> Withdrawn drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mophe_path = \"gs://open-targets-data-releases/24.09/output/etl/parquet/mousePhenotypes\"\n",
    "mophe = spark.read.parquet(mophe_path)\n",
    "\n",
    "target_path = \"gs://open-targets-data-releases/24.09/output/etl/parquet/targets/\"\n",
    "target = spark.read.parquet(target_path)\n",
    "\n",
    "mopheScore_path = \"gs://ot-team/jroldan/20230825_mousePheScores.csv\"\n",
    "mopheScore = spark.read.csv(mopheScore_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonic_sum(evidence_scores):\n",
    "    harmonic_sum = sum(\n",
    "        score / ((i + 1) ** (2)) for i, score in enumerate(evidence_scores)\n",
    "    )\n",
    "    return harmonic_sum\n",
    "\n",
    "\n",
    "def max_harmonic_sum(evidence_scores):\n",
    "    max_theoretical_harmonic_sum = sum(\n",
    "        1 / ((i + 1) ** (2)) for i in range(len(evidence_scores))\n",
    "    )\n",
    "    return max_theoretical_harmonic_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make dataset of targets with safety Liabilities.\n",
    "    There are multiple safety liabitily types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> See how many differents datasource of safety liabilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:=============================>                            (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+\n",
      "|datasource           |count|\n",
      "+---------------------+-----+\n",
      "|Force et al. (2011)  |47   |\n",
      "|null                 |62180|\n",
      "|Lamore et al. (2017) |30   |\n",
      "|Brennan et al. (2024)|210  |\n",
      "|AOP-Wiki             |227  |\n",
      "|Lynch et al. (2017)  |1341 |\n",
      "|Bowes et al. (2012)  |313  |\n",
      "|Urban et al. (2012)  |254  |\n",
      "|ToxCast              |375  |\n",
      "|PharmGKB             |1661 |\n",
      "+---------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    target.select(\"id\", F.explode_outer(F.col(\"safetyLiabilities\")).alias(\"safeLiable\"))\n",
    "    .select(\"id\", \"safeLiable.*\")\n",
    "    .groupBy(\"datasource\")\n",
    "    .count()\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove datasources of Brennan et al (2024) and PharmGKB (Pharmacogenetics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### safety liabilities without Brennan and PGx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 84:====================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 503 targets with safety liabilities excluding Brennan 2024 and PGx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "safetyLiability = (\n",
    "    target.select(\"id\", F.explode_outer(F.col(\"safetyLiabilities\")).alias(\"safeLiable\"))\n",
    "    .select(\"id\", \"safeLiable.*\")\n",
    "    .filter(~F.col(\"datasource\").isin([\"Brennan et al. (2024)\", \"PharmGKB\"]))\n",
    "    .select(\"id\", \"event\")\n",
    "    .groupBy(\"id\")\n",
    "    .agg(F.count(\"event\").alias(\"nr\"))\n",
    "    .sort(F.col(\"nr\").asc())\n",
    ")\n",
    "n = safetyLiability.count()\n",
    "print(\"There are\", n, \"targets with safety liabilities excluding Brennan 2024 and PGx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### genetic constraint and lof_tolerance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "constr = (\n",
    "    target.select(\"id\", F.explode_outer(F.col(\"constraint\")).alias(\"genConstraint\"))\n",
    "    .select(\"id\", \"genConstraint.*\")\n",
    "    .filter(\n",
    "        F.col(\"constraintType\")\n",
    "        == \"lof\"\n",
    "        # ).sort(F.col(\"upperRank\").desc()\n",
    "    )\n",
    "    .select(\n",
    "        \"id\",\n",
    "        \"upperRank\",\n",
    "        \"oe\",\n",
    "        F.col(\"score\").alias(\"scoreConstraint\"),\n",
    "    )\n",
    ")\n",
    "minUpperRank = (\n",
    "    target.select(F.col(\"id\").alias(\"constr_id\"), F.explode(\"constraint\"))\n",
    "    .select(F.col(\"col.*\"))\n",
    "    .filter(F.col(\"constraintType\") == \"lof\")\n",
    "    .groupBy(\"constraintType\")\n",
    "    .agg(F.min(\"upperRank\").alias(\"upperRank\"))\n",
    "    .select(\"upperRank\")\n",
    "    .rdd.flatMap(lambda x: x)\n",
    "    .collect()[0]\n",
    ")\n",
    "\n",
    "maxUpperRank = (\n",
    "    target.select(F.col(\"id\").alias(\"constr_id\"), F.explode(\"constraint\"))\n",
    "    .select(F.col(\"col.*\"))\n",
    "    .filter(F.col(\"constraintType\") == \"lof\")\n",
    "    .groupBy(\"constraintType\")\n",
    "    .agg(F.max(\"upperRank\").alias(\"upperRank\"))\n",
    "    .select(\"upperRank\")\n",
    "    .rdd.flatMap(lambda x: x)\n",
    "    .collect()[0]\n",
    ")\n",
    "\n",
    "loftolerance = (\n",
    "    target.select(F.col(\"id\").alias(\"constr_id\"), F.explode(\"constraint\"))\n",
    "    .select(F.col(\"constr_id\"), F.col(\"col.*\"))\n",
    "    .filter(F.col(\"constraintType\") == \"lof\")\n",
    "    .withColumn(\n",
    "        \"cal_score\",\n",
    "        F.lit(\n",
    "            (2 * ((F.col(\"upperRank\") - minUpperRank) / (maxUpperRank - minUpperRank)))\n",
    "            - 1\n",
    "        ),\n",
    "    )\n",
    "    .selectExpr(\"constr_id as id\", \"cal_score\", \"constraintType\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mouse score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mousePhenoScoreFilter = mopheScore.select(\n",
    "    F.col(\"id\").alias(\"idLabel\"),\n",
    "    F.col(\"label\").alias(\"phenoLabel\"),\n",
    "    F.col(\"score\"),\n",
    ").withColumn(\n",
    "    \"curatedScore\",\n",
    "    F.when(F.col(\"score\") == 0.0, F.lit(0)).otherwise(F.lit(F.col(\"score\"))),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mouse score per target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreCalc_list = (\n",
    "    mophe.select(\n",
    "        \"targetFromSourceId\",\n",
    "        F.explode_outer(F.col(\"modelPhenotypeClasses.id\")).alias(\"id\"),\n",
    "    )\n",
    "    .join(mousePhenoScoreFilter, F.col(\"id\") == mousePhenoScoreFilter.idLabel, \"left\")\n",
    "    ##.na.drop(subset=['scoreRevisado3'])\n",
    "    .withColumn(\"score\", F.col(\"curatedScore\").cast(FloatType()))\n",
    "    .groupBy(\"targetFromSourceId\")\n",
    "    .agg(array_to_vector(F.collect_list(\"score\")).alias(\"score\"))\n",
    "    #    .join(constr.select(\"constr_id\",\"upperRank\"), constr.constr_id == F.col(\"targetFromSourceId\"),\"left\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Safety WO ToxCast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 96:==============>                                           (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 262  targets with safety liabilities excluding ToxCast, Brennan 2024 and PGx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "safetyWOToxCast = (\n",
    "    target.select(\"id\", F.explode_outer(F.col(\"safetyLiabilities\")).alias(\"safeLiable\"))\n",
    "    .filter(\n",
    "        ~F.col(\"safeLiable.datasource\").isin(\n",
    "            [\"ToxCast\", \"Brennan et al. (2024)\", \"PharmGKB\"]\n",
    "        )\n",
    "    )\n",
    "    .select(\"id\", \"safeLiable.*\")\n",
    "    .select(\"id\", \"event\")\n",
    "    .groupBy(\"id\")\n",
    "    .agg(F.count(\"event\").alias(\"noToxCast\"))\n",
    "    .sort(F.col(\"noToxCast\").asc())\n",
    ")\n",
    "\n",
    "n = safetyWOToxCast.count()\n",
    "print(\n",
    "    \"There are\",\n",
    "    n,\n",
    "    \" targets with safety liabilities excluding ToxCast, Brennan 2024 and PGx\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### approved Drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "approvedTargets = spark.read.csv(\n",
    "    \"gs://ot-team/jroldan/2013-2022_approvals.csv\", header=True\n",
    ").drop(\"_c0\")\n",
    "approved = approvedTargets.select(\"targetIds\")\n",
    "\n",
    "\n",
    "def remove_all_whitespace(col):\n",
    "    return F.regexp_replace(col, \"\\\\s+\", \"\")\n",
    "\n",
    "\n",
    "approvedTargets = (\n",
    "    approved.withColumn(\"targets\", (F.explode(F.split(F.col(\"targetIds\"), \";\"))))\n",
    "    .withColumn(\"trimmed\", F.trim(F.col(\"targets\")))\n",
    "    .selectExpr(\"trimmed as id\")\n",
    "    .withColumn(\"approved\", F.lit(\"approved\"))\n",
    "    .distinct()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Score from mouse phenotypes using harmonic sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_py = scoreCalc_list.toPandas()\n",
    "\n",
    "values = []\n",
    "for row in df_py[\"score\"]:\n",
    "    z = sorted(row, reverse=True)\n",
    "    values.append(harmonic_sum(z))\n",
    "\n",
    "maximumScore = 1.644\n",
    "\n",
    "df_py[\"harmonicSum\"] = values\n",
    "normalised = []\n",
    "for row in df_py[\"harmonicSum\"]:\n",
    "    new = row / (maximumScore)\n",
    "    normalised.append(new)\n",
    "df_py[\"harmonicSumNorm\"] = normalised\n",
    "\n",
    "## convert pandas to spark dataframe\n",
    "df = spark.createDataFrame(df_py).withColumnRenamed(\"targetFromSourceId\", \"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run DoE to have LoF and GoF drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/27 19:57:58 WARN CacheManager: Asked to cache already cached data.\n",
      "24/09/27 19:57:59 WARN CacheManager: Asked to cache already cached data.\n",
      "24/09/27 19:57:59 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
   "source": [
    "evidences = (\n",
    "    spark.read.parquet(\n",
    "        \"gs://open-targets-data-releases/24.06/output/etl/parquet/evidence\"\n",
    "    )\n",
    "    .filter(\n",
    "        F.col(\"datasourceId\").isin(\n",
    "            [\n",
    "                \"ot_genetics_portal\",\n",
    "                \"gene_burden\",\n",
    "                \"eva\",\n",
    "                \"eva_somatic\",\n",
    "                \"gene2phenotype\",\n",
    "                \"orphanet\",\n",
    "                \"cancer_gene_census\",\n",
    "                \"intogen\",\n",
    "                \"impc\",\n",
    "                \"chembl\",\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    .persist()\n",
    ")\n",
    "platform_v = \"24.09\"\n",
    "dataset = directionOfEffect(evidences, platform_v).persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Drug warnings to take Black Box Warning Drugs and Withdrawn Drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugWarning_path = (\n",
    "    \"gs://open-targets-data-releases/24.09/output/etl/parquet/drugWarnings\"\n",
    ")\n",
    "drugwarnings = spark.read.parquet(drugWarning_path)\n",
    "\n",
    "#### filter Drugs by inhibitors (LoF)\n",
    "lofDrugs = (\n",
    "    dataset.filter(F.col(\"datasourceId\") == \"chembl\")\n",
    "    .select(\"targetId\", \"drugId\", \"homogenized\")\n",
    "    .filter(F.col(\"homogenized\") == \"LoF_protect\")\n",
    "    .groupBy(\"targetId\", \"drugId\")\n",
    "    .count()\n",
    ")\n",
    "\n",
    "lofDrugsWarnings = lofDrugs.join(\n",
    "    drugwarnings.withColumn(\"drugId\", F.explode_outer(\"chemblIds\")).select(\n",
    "        \"drugId\", \"toxicityClass\", \"warningType\"\n",
    "    ),\n",
    "    on=\"drugId\",\n",
    "    how=\"left\",\n",
    ").distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Drugs with BBW to Targets with BBW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "suffix_bbw = \"_BBW\"\n",
    "\n",
    "lofDrugWarningBBX = (\n",
    "    lofDrugsWarnings.filter(F.col(\"warningType\") == \"Black Box Warning\")\n",
    "    .groupBy(\"targetId\")\n",
    "    .pivot(\"toxicityClass\")\n",
    "    .agg(F.collect_set(\"warningType\"))\n",
    ")\n",
    "\n",
    "array_columns = lofDrugWarningBBX.columns[1:]\n",
    "\n",
    "# The value to check in the arrays\n",
    "value_to_check = \"Black Box Warning\"\n",
    "\n",
    "# Create a new DataFrame with transformed columns\n",
    "df_transformed = lofDrugWarningBBX\n",
    "\n",
    "for col_name in array_columns:\n",
    "    new_col_name = f\"{col_name}_BBW\"\n",
    "    df_transformed = df_transformed.withColumn(\n",
    "        new_col_name,\n",
    "        F.when(F.array_contains(F.col(col_name), value_to_check), 1).otherwise(0),\n",
    "    )\n",
    "\n",
    "lofDrugWarningBBX_format = df_transformed.drop(*array_columns).withColumn(\n",
    "    \"allBBW\", F.lit(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Drugs with WithDrawn to Targets with withDrawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lofDrugWarningWD = (\n",
    "    lofDrugsWarnings.filter(F.col(\"warningType\") == \"Withdrawn\")\n",
    "    .groupBy(\"targetId\")\n",
    "    .pivot(\"toxicityClass\")\n",
    "    .agg(F.collect_set(\"warningType\"))\n",
    ")\n",
    "\n",
    "array_columns = lofDrugWarningWD.columns[1:]\n",
    "\n",
    "# The value to check in the arrays\n",
    "value_to_check = \"Withdrawn\"\n",
    "\n",
    "# Create a new DataFrame with transformed columns\n",
    "df_transformed = lofDrugWarningWD\n",
    "\n",
    "for col_name in array_columns:\n",
    "    new_col_name = f\"{col_name}_WD\"\n",
    "    df_transformed = df_transformed.withColumn(\n",
    "        new_col_name,\n",
    "        F.when(F.array_contains(F.col(col_name), value_to_check), 1).otherwise(0),\n",
    "    )\n",
    "\n",
    "lofDrugWarningWD_format = df_transformed.drop(*array_columns).withColumn(\n",
    "    \"allWD\", F.lit(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join Drugs BBW and Drugs WithDrawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lofDrugsBBw_WD = (\n",
    "    lofDrugWarningWD_format.join(lofDrugWarningBBX_format, on=\"targetId\", how=\"outer\")\n",
    "    .withColumn(\"bwwAndwd\", F.lit(1))\n",
    "    .na.fill(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset and prepare normalized harmonic sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### make dataset for comparisons\n",
    "df_comparisons = (\n",
    "    df.join(loftolerance, on=\"id\", how=\"left\")\n",
    "    .join(safetyLiability, on=\"id\", how=\"left\")\n",
    "    .join(safetyWOToxCast, on=\"id\", how=\"left\")\n",
    "    .join(approvedTargets, on=\"id\", how=\"left\")\n",
    "    .join(lofDrugsBBw_WD.withColumnRenamed(\"targetId\", \"id\"), on=\"id\", how=\"left\")\n",
    "    .withColumn(\"allBBW\", F.when(F.col(\"allBBW\") == 1, F.lit(1)).otherwise(F.lit(0)))\n",
    "    .withColumn(\"allWD\", F.when(F.col(\"allWD\") == 1, F.lit(1)).otherwise(F.lit(0)))\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "#### Make deciles for harmonic sum\n",
    "# Calculate quartiles or deciles\n",
    "quantiles = df_comparisons.approxQuantile(\n",
    "    \"harmonicSumNorm\", [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 0.01\n",
    ")\n",
    "# Define quartile or decile bins\n",
    "bins = [float(\"-inf\")] + quantiles + [float(\"inf\")]\n",
    "window_spec = Window.orderBy(\"harmonicSumNorm\")\n",
    "df_with_labels = (\n",
    "    df_comparisons.withColumn(\n",
    "        \"decilesHarmonicSumNorm\",\n",
    "        F.when(F.col(\"harmonicSumNorm\").isNull(), None).otherwise(\n",
    "            sum(\n",
    "                F.when(F.col(\"harmonicSumNorm\") >= bin_val, 1).otherwise(0)\n",
    "                for bin_val in bins\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"safetyLiabilities\", F.when(F.col(\"nr\").isNotNull(), F.lit(1)).otherwise(0)\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"noToxCastLiab\", F.when(F.col(\"noToxCast\").isNotNull(), F.lit(1)).otherwise(0)\n",
    "    )\n",
    "    .drop(\"nr\", \"noToxCast\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use human genetics to define the Severity Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
