{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Window\n",
    "import pyspark.sql.functions as F\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    DoubleType,\n",
    "    DecimalType,\n",
    "    StringType,\n",
    "    FloatType,\n",
    ")\n",
    "from functions import directionOfEffect\n",
    "from pyspark.ml.functions import array_to_vector, vector_to_array\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can we use mouse phenotypes for: \n",
    "    >> Predict Safety Liabilities\n",
    "    >> Drug warnings (Black Box Warnings)\n",
    "    >> Withdrawn drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mophe_path = \"gs://open-targets-data-releases/24.09/output/etl/parquet/mousePhenotypes\"\n",
    "mophe = spark.read.parquet(mophe_path)\n",
    "\n",
    "target_path = \"gs://open-targets-data-releases/24.09/output/etl/parquet/targets/\"\n",
    "target = spark.read.parquet(target_path)\n",
    "\n",
    "mopheScore_path = \"gs://ot-team/jroldan/20230825_mousePheScores.csv\"\n",
    "mopheScore = spark.read.csv(mopheScore_path, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make dataset of targets with safety Liabilities.\n",
    "    There are multiple safety liabitily types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> See how many differents datasource of safety liabilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:=============================>                            (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+\n",
      "|datasource           |count|\n",
      "+---------------------+-----+\n",
      "|Force et al. (2011)  |47   |\n",
      "|null                 |62180|\n",
      "|Lamore et al. (2017) |30   |\n",
      "|Brennan et al. (2024)|210  |\n",
      "|AOP-Wiki             |227  |\n",
      "|Lynch et al. (2017)  |1341 |\n",
      "|Bowes et al. (2012)  |313  |\n",
      "|Urban et al. (2012)  |254  |\n",
      "|ToxCast              |375  |\n",
      "|PharmGKB             |1661 |\n",
      "+---------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    target.select(\"id\", F.explode_outer(F.col(\"safetyLiabilities\")).alias(\"safeLiable\"))\n",
    "    .select(\"id\", \"safeLiable.*\")\n",
    "    .groupBy(\"datasource\")\n",
    "    .count()\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove datasources of Brennan et al (2024) and PharmGKB (Pharmacogenetics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### safety liabilities without Brennan and PGx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 215:===============================>                        (9 + 7) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 503 targets with safety liabilities excluding Brennan 2024 and PGx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "safetyLiability = (\n",
    "    target.select(\"id\", F.explode_outer(F.col(\"safetyLiabilities\")).alias(\"safeLiable\"))\n",
    "    .select(\"id\", \"safeLiable.*\")\n",
    "    .filter(~F.col(\"datasource\").isin([\"Brennan et al. (2024)\", \"PharmGKB\"]))\n",
    "    .select(\"id\", \"event\")\n",
    "    .groupBy(\"id\")\n",
    "    .agg(F.count(\"event\").alias(\"safetyLiabl\"))\n",
    "    .sort(F.col(\"safetyLiabl\").asc())\n",
    ")\n",
    "n = safetyLiability.count()\n",
    "print(\"There are\", n, \"targets with safety liabilities excluding Brennan 2024 and PGx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### genetic constraint and lof_tolerance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "constr = (\n",
    "    target.select(\"id\", F.explode_outer(F.col(\"constraint\")).alias(\"genConstraint\"))\n",
    "    .select(\"id\", \"genConstraint.*\")\n",
    "    .filter(\n",
    "        F.col(\"constraintType\")\n",
    "        == \"lof\"\n",
    "        # ).sort(F.col(\"upperRank\").desc()\n",
    "    )\n",
    "    .select(\n",
    "        \"id\",\n",
    "        \"upperRank\",\n",
    "        \"oe\",\n",
    "        F.col(\"score\").alias(\"scoreConstraint\"),\n",
    "    )\n",
    ")\n",
    "minUpperRank = (\n",
    "    target.select(F.col(\"id\").alias(\"constr_id\"), F.explode(\"constraint\"))\n",
    "    .select(F.col(\"col.*\"))\n",
    "    .filter(F.col(\"constraintType\") == \"lof\")\n",
    "    .groupBy(\"constraintType\")\n",
    "    .agg(F.min(\"upperRank\").alias(\"upperRank\"))\n",
    "    .select(\"upperRank\")\n",
    "    .rdd.flatMap(lambda x: x)\n",
    "    .collect()[0]\n",
    ")\n",
    "\n",
    "maxUpperRank = (\n",
    "    target.select(F.col(\"id\").alias(\"constr_id\"), F.explode(\"constraint\"))\n",
    "    .select(F.col(\"col.*\"))\n",
    "    .filter(F.col(\"constraintType\") == \"lof\")\n",
    "    .groupBy(\"constraintType\")\n",
    "    .agg(F.max(\"upperRank\").alias(\"upperRank\"))\n",
    "    .select(\"upperRank\")\n",
    "    .rdd.flatMap(lambda x: x)\n",
    "    .collect()[0]\n",
    ")\n",
    "\n",
    "loftolerance = (\n",
    "    target.select(F.col(\"id\").alias(\"constr_id\"), F.explode(\"constraint\"))\n",
    "    .select(F.col(\"constr_id\"), F.col(\"col.*\"))\n",
    "    .filter(F.col(\"constraintType\") == \"lof\")\n",
    "    .withColumn(\n",
    "        \"cal_score\",\n",
    "        F.lit(\n",
    "            (2 * ((F.col(\"upperRank\") - minUpperRank) / (maxUpperRank - minUpperRank)))\n",
    "            - 1\n",
    "        ),\n",
    "    )\n",
    "    .selectExpr(\"constr_id as id\", \"cal_score\", \"constraintType\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mouse score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mousePhenoScoreFilter = mopheScore.select(\n",
    "    F.col(\"id\").alias(\"idLabel\"),\n",
    "    F.col(\"label\").alias(\"phenoLabel\"),\n",
    "    F.col(\"score\"),\n",
    ").withColumn(\n",
    "    \"curatedScore\",\n",
    "    F.when(F.col(\"score\") == 0.0, F.lit(0)).otherwise(F.lit(F.col(\"score\"))),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mouse score per target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreCalc_list = (\n",
    "    mophe.select(\n",
    "        \"targetFromSourceId\",\n",
    "        F.explode_outer(F.col(\"modelPhenotypeClasses.id\")).alias(\"id\"),\n",
    "    )\n",
    "    .join(mousePhenoScoreFilter, F.col(\"id\") == mousePhenoScoreFilter.idLabel, \"left\")\n",
    "    ##.na.drop(subset=['scoreRevisado3'])\n",
    "    .withColumn(\"score\", F.col(\"curatedScore\").cast(FloatType()))\n",
    "    .groupBy(\"targetFromSourceId\")\n",
    "    .agg(array_to_vector(F.collect_list(\"score\")).alias(\"score\"))\n",
    "    #    .join(constr.select(\"constr_id\",\"upperRank\"), constr.constr_id == F.col(\"targetFromSourceId\"),\"left\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Safety WO ToxCast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 96:==============>                                           (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 262  targets with safety liabilities excluding ToxCast, Brennan 2024 and PGx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "safetyWOToxCast = (\n",
    "    target.select(\"id\", F.explode_outer(F.col(\"safetyLiabilities\")).alias(\"safeLiable\"))\n",
    "    .filter(\n",
    "        ~F.col(\"safeLiable.datasource\").isin(\n",
    "            [\"ToxCast\", \"Brennan et al. (2024)\", \"PharmGKB\"]\n",
    "        )\n",
    "    )\n",
    "    .select(\"id\", \"safeLiable.*\")\n",
    "    .select(\"id\", \"event\")\n",
    "    .groupBy(\"id\")\n",
    "    .agg(F.count(\"event\").alias(\"noToxCast\"))\n",
    "    .sort(F.col(\"noToxCast\").asc())\n",
    ")\n",
    "\n",
    "n = safetyWOToxCast.count()\n",
    "print(\n",
    "    \"There are\",\n",
    "    n,\n",
    "    \" targets with safety liabilities excluding ToxCast, Brennan 2024 and PGx\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### approved Drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "approvedTargets = spark.read.csv(\n",
    "    \"gs://ot-team/jroldan/2013-2022_approvals.csv\", header=True\n",
    ").drop(\"_c0\")\n",
    "approved = approvedTargets.select(\"targetIds\")\n",
    "\n",
    "\n",
    "def remove_all_whitespace(col):\n",
    "    return F.regexp_replace(col, \"\\\\s+\", \"\")\n",
    "\n",
    "\n",
    "approvedTargets = (\n",
    "    approved.withColumn(\"targets\", (F.explode(F.split(F.col(\"targetIds\"), \";\"))))\n",
    "    .withColumn(\"trimmed\", F.trim(F.col(\"targets\")))\n",
    "    .selectExpr(\"trimmed as id\")\n",
    "    .withColumn(\"approved\", F.lit(\"approved\"))\n",
    "    .distinct()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Score from mouse phenotypes using harmonic sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_py = scoreCalc_list.toPandas()\n",
    "\n",
    "values = []\n",
    "for row in df_py[\"score\"]:\n",
    "    z = sorted(row, reverse=True)\n",
    "    values.append(harmonic_sum(z))\n",
    "\n",
    "maximumScore = 1.644\n",
    "\n",
    "df_py[\"harmonicSum\"] = values\n",
    "normalised = []\n",
    "for row in df_py[\"harmonicSum\"]:\n",
    "    new = row / (maximumScore)\n",
    "    normalised.append(new)\n",
    "df_py[\"harmonicSumNorm\"] = normalised\n",
    "\n",
    "## convert pandas to spark dataframe\n",
    "df = spark.createDataFrame(df_py).withColumnRenamed(\"targetFromSourceId\", \"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run DoE to have LoF and GoF drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/27 19:57:58 WARN CacheManager: Asked to cache already cached data.\n",
      "24/09/27 19:57:59 WARN CacheManager: Asked to cache already cached data.\n",
      "24/09/27 19:57:59 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
   "source": [
    "evidences = (\n",
    "    spark.read.parquet(\n",
    "        \"gs://open-targets-data-releases/24.06/output/etl/parquet/evidence\"\n",
    "    )\n",
    "    .filter(\n",
    "        F.col(\"datasourceId\").isin(\n",
    "            [\n",
    "                \"ot_genetics_portal\",\n",
    "                \"gene_burden\",\n",
    "                \"eva\",\n",
    "                \"eva_somatic\",\n",
    "                \"gene2phenotype\",\n",
    "                \"orphanet\",\n",
    "                \"cancer_gene_census\",\n",
    "                \"intogen\",\n",
    "                \"impc\",\n",
    "                \"chembl\",\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    .persist()\n",
    ")\n",
    "platform_v = \"24.09\"\n",
    "dataset = directionOfEffect(evidences, platform_v).persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Drug warnings to take Black Box Warning Drugs and Withdrawn Drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugWarning_path = (\n",
    "    \"gs://open-targets-data-releases/24.09/output/etl/parquet/drugWarnings\"\n",
    ")\n",
    "drugwarnings = spark.read.parquet(drugWarning_path)\n",
    "\n",
    "#### filter Drugs by inhibitors (LoF)\n",
    "lofDrugs = (\n",
    "    dataset.filter(F.col(\"datasourceId\") == \"chembl\")\n",
    "    .select(\"targetId\", \"drugId\", \"homogenized\")\n",
    "    .filter(F.col(\"homogenized\") == \"LoF_protect\")\n",
    "    .groupBy(\"targetId\", \"drugId\")\n",
    "    .count()\n",
    ")\n",
    "\n",
    "lofDrugsWarnings = lofDrugs.join(\n",
    "    drugwarnings.withColumn(\"drugId\", F.explode_outer(\"chemblIds\")).select(\n",
    "        \"drugId\", \"toxicityClass\", \"warningType\"\n",
    "    ),\n",
    "    on=\"drugId\",\n",
    "    how=\"left\",\n",
    ").distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Drugs with BBW to Targets with BBW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "suffix_bbw = \"_BBW\"\n",
    "\n",
    "lofDrugWarningBBX = (\n",
    "    lofDrugsWarnings.filter(F.col(\"warningType\") == \"Black Box Warning\")\n",
    "    .groupBy(\"targetId\")\n",
    "    .pivot(\"toxicityClass\")\n",
    "    .agg(F.collect_set(\"warningType\"))\n",
    ")\n",
    "\n",
    "array_columns = lofDrugWarningBBX.columns[1:]\n",
    "\n",
    "# The value to check in the arrays\n",
    "value_to_check = \"Black Box Warning\"\n",
    "\n",
    "# Create a new DataFrame with transformed columns\n",
    "df_transformed = lofDrugWarningBBX\n",
    "\n",
    "for col_name in array_columns:\n",
    "    new_col_name = f\"{col_name}_BBW\"\n",
    "    df_transformed = df_transformed.withColumn(\n",
    "        new_col_name,\n",
    "        F.when(F.array_contains(F.col(col_name), value_to_check), 1).otherwise(0),\n",
    "    )\n",
    "\n",
    "lofDrugWarningBBX_format = df_transformed.drop(*array_columns).withColumn(\n",
    "    \"allBBW\", F.lit(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Drugs with WithDrawn to Targets with withDrawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lofDrugWarningWD = (\n",
    "    lofDrugsWarnings.filter(F.col(\"warningType\") == \"Withdrawn\")\n",
    "    .groupBy(\"targetId\")\n",
    "    .pivot(\"toxicityClass\")\n",
    "    .agg(F.collect_set(\"warningType\"))\n",
    ")\n",
    "\n",
    "array_columns = lofDrugWarningWD.columns[1:]\n",
    "\n",
    "# The value to check in the arrays\n",
    "value_to_check = \"Withdrawn\"\n",
    "\n",
    "# Create a new DataFrame with transformed columns\n",
    "df_transformed = lofDrugWarningWD\n",
    "\n",
    "for col_name in array_columns:\n",
    "    new_col_name = f\"{col_name}_WD\"\n",
    "    df_transformed = df_transformed.withColumn(\n",
    "        new_col_name,\n",
    "        F.when(F.array_contains(F.col(col_name), value_to_check), 1).otherwise(0),\n",
    "    )\n",
    "\n",
    "lofDrugWarningWD_format = df_transformed.drop(*array_columns).withColumn(\n",
    "    \"allWD\", F.lit(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join Drugs BBW and Drugs WithDrawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lofDrugsBBw_WD = (\n",
    "    lofDrugWarningWD_format.join(lofDrugWarningBBX_format, on=\"targetId\", how=\"outer\")\n",
    "    .withColumn(\"bwwAndwd\", F.lit(1))\n",
    "    .na.fill(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset and prepare normalized harmonic sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### make dataset for comparisons\n",
    "df_comparisons = (\n",
    "    df.join(loftolerance, on=\"id\", how=\"left\")\n",
    "    .join(safetyLiability, on=\"id\", how=\"left\")\n",
    "    .join(safetyWOToxCast, on=\"id\", how=\"left\")\n",
    "    .join(approvedTargets, on=\"id\", how=\"left\")\n",
    "    .join(lofDrugsBBw_WD.withColumnRenamed(\"targetId\", \"id\"), on=\"id\", how=\"left\")\n",
    "    .withColumn(\"allBBW\", F.when(F.col(\"allBBW\") == 1, F.lit(1)).otherwise(F.lit(0)))\n",
    "    .withColumn(\"allWD\", F.when(F.col(\"allWD\") == 1, F.lit(1)).otherwise(F.lit(0)))\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "#### Make deciles for harmonic sum\n",
    "# Calculate quartiles or deciles\n",
    "quantiles = df_comparisons.approxQuantile(\n",
    "    \"harmonicSumNorm\", [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 0.01\n",
    ")\n",
    "# Define quartile or decile bins\n",
    "bins = [float(\"-inf\")] + quantiles + [float(\"inf\")]\n",
    "window_spec = Window.orderBy(\"harmonicSumNorm\")\n",
    "df_with_labels = (\n",
    "    df_comparisons.withColumn(\n",
    "        \"decilesHarmonicSumNorm\",\n",
    "        F.when(F.col(\"harmonicSumNorm\").isNull(), None).otherwise(\n",
    "            sum(\n",
    "                F.when(F.col(\"harmonicSumNorm\") >= bin_val, 1).otherwise(0)\n",
    "                for bin_val in bins\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"safetyLiabilities\", F.when(F.col(\"nr\").isNotNull(), F.lit(1)).otherwise(0)\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"noToxCastLiab\", F.when(F.col(\"noToxCast\").isNotNull(), F.lit(1)).otherwise(0)\n",
    "    )\n",
    "    .drop(\"nr\", \"noToxCast\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use human genetics to define the Severity Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Define disease types (Rare or Common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rare diseases\n",
    "rare = [\n",
    "    \"eva\",\n",
    "    \"cancer_gene_census\",\n",
    "    \"eva_somatic\",\n",
    "    \"orphanet\",\n",
    "    \"genomics_england\",\n",
    "    \"gene2phenotype\",\n",
    "    \"intogen\",\n",
    "]\n",
    "\n",
    "## common diseases\n",
    "common = [\"ot_genetics_portal\", \"gene_burden\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "diseaseTypes = (  ### association of target with diseases caused by (LoF risk)\n",
    "    dataset.withColumn(\n",
    "        \"diseaseType\",\n",
    "        F.when(F.col(\"datasourceId\").isin(rare), F.lit(\"rare\")).when(\n",
    "            F.col(\"datasourceId\").isin(common), F.lit(\"common\")\n",
    "        ),\n",
    "    )\n",
    "    .filter(\n",
    "        (\n",
    "            F.col(\"homogenized\") == \"LoF_risk\"\n",
    "        )  ### filter by diseases caused by targets with LoF mutations\n",
    "        & (F.col(\"diseaseType\").isNotNull())\n",
    "    )\n",
    "    .groupBy(\"targetId\", \"diseaseId\")\n",
    "    .agg(\n",
    "        F.count(\"targetId\").alias(\"nr\"),\n",
    "        F.collect_set(\"diseaseType\").alias(\"diseaseType\"),\n",
    "    )\n",
    "    .withColumn(\"bivalent\", F.size(F.col(\"diseaseType\")))\n",
    "    # .filter(F.col(\"bivalent\") == 1)\n",
    ").persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### approach rare = severe, common = non severe, rare&common = mid severe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = (\n",
    "    diseaseTypes.groupBy(\"targetId\")\n",
    "    .agg(F.flatten(F.collect_set(\"diseaseType\")).alias(\"diseaseType\"))\n",
    "    .withColumn(\n",
    "        \"scoreFromDisease\",\n",
    "        F.when(\n",
    "            (F.size(F.col(\"diseaseType\")) == 1)\n",
    "            & (F.array_contains(F.col(\"diseaseType\"), \"common\")),\n",
    "            F.lit(0.25),\n",
    "        )\n",
    "        .when(\n",
    "            (F.size(F.col(\"diseaseType\")) == 1)\n",
    "            & (F.array_contains(F.col(\"diseaseType\"), \"rare\")),\n",
    "            F.lit(1),\n",
    "        )\n",
    "        .when(F.size(F.col(\"diseaseType\")) == 2, F.lit(0.7))\n",
    "        .when(F.size(F.col(\"diseaseType\")) == 0, F.lit(0)),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "phenoDiseases = (\n",
    "    mophe.select(\"targetFromSourceId\", \"modelPhenotypeLabel\", \"targetFromSourceId\")\n",
    "    .withColumnRenamed(\"targetFromSourceId\", \"targetId\")\n",
    "    .join(scoring, on=\"targetId\", how=\"right\")\n",
    "    .withColumn(\"typesOfDiseases\", F.explode_outer(F.col(\"diseaseType\")))\n",
    "    .groupBy(\"modelPhenotypeLabel\")\n",
    "    .agg(F.collect_set(\"typesOfDiseases\").alias(\"diseaseType\"))\n",
    "    .withColumn(\n",
    "        \"scoreFromDisease\",\n",
    "        F.when(\n",
    "            (F.size(F.col(\"diseaseType\")) == 1)\n",
    "            & (F.array_contains(F.col(\"diseaseType\"), \"common\")),\n",
    "            F.lit(0.2),\n",
    "        )\n",
    "        .when(\n",
    "            (F.size(F.col(\"diseaseType\")) == 1)\n",
    "            & (F.array_contains(F.col(\"diseaseType\"), \"rare\")),\n",
    "            F.lit(1),\n",
    "        )\n",
    "        .when(\n",
    "            (F.size(F.col(\"diseaseType\")) == 2)\n",
    "            & (F.col(\"modelPhenotypeLabel\").isNotNull()),\n",
    "            F.lit(0.6),\n",
    "        )\n",
    "        .when(F.size(F.col(\"diseaseType\")) == 0, F.lit(0))\n",
    "        .otherwise(F.lit(0)),\n",
    "    )\n",
    ")\n",
    "\n",
    "scoreDiseases1 = (\n",
    "    mophe.select(\"targetFromSourceId\", \"modelPhenotypeLabel\")\n",
    "    .join(phenoDiseases, on=\"modelPhenotypeLabel\", how=\"right\")\n",
    "    .groupBy(\"targetFromSourceId\")\n",
    "    .agg(array_to_vector(F.collect_list(\"scoreFromDisease\")).alias(\"score\"))\n",
    ")\n",
    "\n",
    "df_py = scoreDiseases1.toPandas()\n",
    "\n",
    "values = []\n",
    "for row in df_py[\"score\"]:\n",
    "    z = sorted(row, reverse=True)\n",
    "    values.append(harmonic_sum(z))\n",
    "# maximumScore = max(values)\n",
    "\n",
    "maximumScore = 1.644\n",
    "\n",
    "df_py[\"harmonicSum\"] = values\n",
    "normalised = []\n",
    "for row in df_py[\"harmonicSum\"]:\n",
    "    new = row / (maximumScore)\n",
    "    normalised.append(new)\n",
    "df_py[\"harmonicSumNorm\"] = normalised\n",
    "\n",
    "\n",
    "## convert pandas to spark dataframe\n",
    "df_scoreDisease1 = (\n",
    "    spark.createDataFrame(df_py)\n",
    "    .withColumnRenamed(\"targetFromSourceId\", \"id\")\n",
    "    .selectExpr(\n",
    "        \"id\",\n",
    "        \"score as scoreDiseases1\",\n",
    "        \"harmonicSumNorm as dis1HarmSumNorm\",\n",
    "    )\n",
    "    .filter(F.col(\"id\").isNotNull())\n",
    ")\n",
    "\n",
    "df_comparisons2 = df_comparisons.join(df_scoreDisease1, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Score regarding the evidences relating the target with the disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "phenoDiseases2 = (\n",
    "    evidences.filter(F.col(\"datasourceId\") == \"impc\")\n",
    "    .withColumn(\n",
    "        \"explotedPhenotypes\",\n",
    "        F.explode_outer(F.col(\"diseaseModelAssociatedModelPhenotypes\")),\n",
    "    )\n",
    "    .select(\"targetId\", \"diseaseId\", \"explotedPhenotypes\")\n",
    "    .join(\n",
    "        diseaseTypes.select(\"diseaseId\", \"diseaseType\", \"bivalent\"),\n",
    "        on=\"diseaseId\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"scoreFromDisease\",\n",
    "        F.when(\n",
    "            (F.size(F.col(\"diseaseType\")) == 1)\n",
    "            & (F.array_contains(F.col(\"diseaseType\"), \"common\")),\n",
    "            F.lit(0.2),\n",
    "        )\n",
    "        .when(\n",
    "            (F.size(F.col(\"diseaseType\")) == 1)\n",
    "            & (F.array_contains(F.col(\"diseaseType\"), \"rare\")),\n",
    "            F.lit(1),\n",
    "        )\n",
    "        .when(\n",
    "            (F.size(F.col(\"diseaseType\")) == 2),\n",
    "            F.lit(0.6),\n",
    "        )\n",
    "        .when(F.size(F.col(\"diseaseType\")) == 0, F.lit(0))\n",
    "        .otherwise(F.lit(0)),\n",
    "    )\n",
    "    .groupBy(\"explotedPhenotypes\")\n",
    "    .agg(F.collect_set(\"scoreFromDisease\").alias(\"scores\"))\n",
    "    .withColumn(\"NrScores\", F.size(\"scores\"))\n",
    "    .withColumn(\n",
    "        \"average\",\n",
    "        F.expr(\"aggregate(scores, 0D, (acc, x) -> acc + x, acc -> acc / size(scores))\"),\n",
    "    )\n",
    ").persist()\n",
    "\n",
    "scoreDiseases2 = (\n",
    "    mophe.select(\"targetFromSourceId\", \"modelPhenotypeLabel\")\n",
    "    .join(\n",
    "        phenoDiseases2.selectExpr(\n",
    "            \"explotedPhenotypes.label as modelPhenotypeLabel\", \"average\"\n",
    "        ),\n",
    "        on=\"modelPhenotypeLabel\",\n",
    "        how=\"right\",\n",
    "    )\n",
    "    .groupBy(\"targetFromSourceId\")\n",
    "    .agg(array_to_vector(F.collect_list(\"average\")).alias(\"score\"))\n",
    ")\n",
    "\n",
    "df_py = scoreDiseases2.toPandas()\n",
    "\n",
    "values = []\n",
    "for row in df_py[\"score\"]:\n",
    "    z = sorted(row, reverse=True)\n",
    "    values.append(harmonic_sum(z))\n",
    "# maximumScore = max(values)\n",
    "\n",
    "maximumScore = 1.644\n",
    "\n",
    "df_py[\"harmonicSum\"] = values\n",
    "normalised = []\n",
    "for row in df_py[\"harmonicSum\"]:\n",
    "    new = row / (maximumScore)\n",
    "    normalised.append(new)\n",
    "df_py[\"harmonicSumNorm\"] = normalised\n",
    "\n",
    "\n",
    "## convert pandas to spark dataframe\n",
    "df_scoreDisease2 = (\n",
    "    spark.createDataFrame(df_py)\n",
    "    .withColumnRenamed(\"targetFromSourceId\", \"id\")\n",
    "    .selectExpr(\n",
    "        \"id\",\n",
    "        \"score as scoreDiseases2\",\n",
    "        \"harmonicSumNorm as dis2HarmSumNorm\",\n",
    "    )\n",
    "    .filter(F.col(\"id\").isNotNull())\n",
    ")\n",
    "\n",
    "df_comparisons3 = df_comparisons2.join(df_scoreDisease2, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve for predicting safety liabilities with score Diseases1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- score: vector (nullable = true)\n",
      " |-- harmonicSum: double (nullable = true)\n",
      " |-- harmonicSumNorm: double (nullable = true)\n",
      " |-- cal_score: double (nullable = true)\n",
      " |-- constraintType: string (nullable = true)\n",
      " |-- nr: long (nullable = true)\n",
      " |-- noToxCast: long (nullable = true)\n",
      " |-- approved: string (nullable = true)\n",
      " |-- null_WD: integer (nullable = true)\n",
      " |-- carcinogenicity_WD: integer (nullable = true)\n",
      " |-- cardiotoxicity_WD: integer (nullable = true)\n",
      " |-- dermatological toxicity_WD: integer (nullable = true)\n",
      " |-- gastrointestinal toxicity_WD: integer (nullable = true)\n",
      " |-- hematological toxicity_WD: integer (nullable = true)\n",
      " |-- hepatotoxicity_WD: integer (nullable = true)\n",
      " |-- immune system toxicity_WD: integer (nullable = true)\n",
      " |-- metabolic toxicity_WD: integer (nullable = true)\n",
      " |-- misuse_WD: integer (nullable = true)\n",
      " |-- musculoskeletal toxicity_WD: integer (nullable = true)\n",
      " |-- nephrotoxicity_WD: integer (nullable = true)\n",
      " |-- neurotoxicity_WD: integer (nullable = true)\n",
      " |-- occular toxicity_WD: integer (nullable = true)\n",
      " |-- psychiatric toxicity_WD: integer (nullable = true)\n",
      " |-- respiratory toxicity_WD: integer (nullable = true)\n",
      " |-- vascular toxicity_WD: integer (nullable = true)\n",
      " |-- allWD: integer (nullable = false)\n",
      " |-- null_BBW: integer (nullable = true)\n",
      " |-- carcinogenicity_BBW: integer (nullable = true)\n",
      " |-- cardiotoxicity_BBW: integer (nullable = true)\n",
      " |-- dermatological toxicity_BBW: integer (nullable = true)\n",
      " |-- gastrointestinal toxicity_BBW: integer (nullable = true)\n",
      " |-- hematological toxicity_BBW: integer (nullable = true)\n",
      " |-- hepatotoxicity_BBW: integer (nullable = true)\n",
      " |-- immune system toxicity_BBW: integer (nullable = true)\n",
      " |-- infectious disease_BBW: integer (nullable = true)\n",
      " |-- metabolic toxicity_BBW: integer (nullable = true)\n",
      " |-- misuse_BBW: integer (nullable = true)\n",
      " |-- musculoskeletal toxicity_BBW: integer (nullable = true)\n",
      " |-- nephrotoxicity_BBW: integer (nullable = true)\n",
      " |-- neurotoxicity_BBW: integer (nullable = true)\n",
      " |-- psychiatric toxicity_BBW: integer (nullable = true)\n",
      " |-- respiratory toxicity_BBW: integer (nullable = true)\n",
      " |-- teratogenicity_BBW: integer (nullable = true)\n",
      " |-- vascular toxicity_BBW: integer (nullable = true)\n",
      " |-- allBBW: integer (nullable = false)\n",
      " |-- bwwAndwd: integer (nullable = true)\n",
      " |-- scoreDiseases1: vector (nullable = true)\n",
      " |-- dis1HarmSumNorm: double (nullable = true)\n",
      " |-- scoreDiseases2: vector (nullable = true)\n",
      " |-- dis2HarmSumNorm: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_comparisons3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### roc curve for Safety Liabilities containing ToxCast:\n",
    "targetPredictedToxCastNO = df_comparisons3.filter(\n",
    "    F.col(\"safetyLiablEventN\") == 1\n",
    ").withColumn(\"y\", F.lit(1))\n",
    "targetWOPredictedToxCastNo = (\n",
    "    df_with_labels8.filter(F.col(\"safetyLiablEventN\") == 0)\n",
    "    .sample(False, 0.5, seed=0)\n",
    "    .limit(469)\n",
    "    .withColumn(\"y\", F.lit(0))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### harmonicsumnormDiseases1\n",
    "\n",
    "targetsToCheckTargetNoToxCast = targetPredictedToxCastNO.union(\n",
    "    targetWOPredictedToxCastNo\n",
    ")\n",
    "## convert to array WO ToxCast\n",
    "y_score_targetPredictToxCast = np.array(\n",
    "    targetsToCheckTargetNoToxCast.select(\"harmonicSumDiseases1\")\n",
    "    .rdd.flatMap(lambda x: x)\n",
    "    .collect()\n",
    ")\n",
    "y_targetPredicttoxCast = np.array(\n",
    "    targetsToCheckTargetNoToxCast.select(\"y\").rdd.flatMap(lambda x: x).collect()\n",
    ")\n",
    "\n",
    "### ROc curve\n",
    "## predicted targets\n",
    "fpr_noToxCastTarget, tpr_noToxCastTarget, thresholds = roc_curve(\n",
    "    y_targetPredicttoxCast, y_score_targetPredictToxCast\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(fpr_noToxCastTarget, tpr_noToxCastTarget)\n",
    "ax.plot([0, 0.5, 1], [0, 0.5, 1])\n",
    "ax.fill_between(fpr_noToxCastTarget, tpr_noToxCastTarget, step=\"pre\", alpha=0.4)\n",
    "ax.set_xlabel(\"False positive rate\")\n",
    "ax.set_ylabel(\"True positive rate\")\n",
    "ax.set_title(\"ROC curve for targets with safety Liabilities (including ToxCast)\")\n",
    "ax.legend(\n",
    "    [\n",
    "        \"HarmonicSumNorm as Predictor\",\n",
    "        \"Random Classifier\",\n",
    "        \"HarmonicSum - AUC {:.3f}\".format(\n",
    "            roc_auc_score(y_targetPredicttoxCast, y_score_targetPredictToxCast)\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
